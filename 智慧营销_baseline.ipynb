{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -n 智慧赢销dataset.zip -d 智慧赢销dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import joblib, re, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 数据预处理 ==================\n",
    "def preprocess_data(df, is_train=True):\n",
    "    \"\"\"基础数据预处理\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 时间特征分解\n",
    "    df['publish_time'] = pd.to_datetime(df['publish_time'], format='%Y%m%d')\n",
    "    df['update_time'] = pd.to_datetime(df['update_time'], format='%Y%m%d')\n",
    "    \n",
    "    # 发布时间特征\n",
    "    df['publish_day'] = df['publish_time'].dt.day\n",
    "    df['publish_weekday'] = df['publish_time'].dt.weekday\n",
    "    df['publish_month'] = df['publish_time'].dt.month\n",
    "    \n",
    "    # 更新时效性特征\n",
    "    df['update_delay_days'] = (df['update_time'] - df['publish_time']).dt.days\n",
    "    \n",
    "    # 数据转换\n",
    "    df['fans_cnt'] = df['fans_cnt'].map({'小于100':50}).fillna(0).astype(int)\n",
    "    df['coin_cnt'] = df['coin_cnt'].map({'小于100':50}).fillna(0).astype(int)\n",
    "    \n",
    "    # 作者基础特征\n",
    "    df['author_popularity'] = df['coin_cnt'] / (df['fans_cnt'] + 1)\n",
    "    df['fans_video_ratio'] = df['fans_cnt'] / (df['video_cnt'] + 1)\n",
    "    df['author_power'] = np.log1p(df['fans_cnt']) * np.log1p(df['coin_cnt'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ================== 文本特征处理 ==================\n",
    "def process_text_features(df, text_columns, n_components=50):\n",
    "    \"\"\"文本特征处理\"\"\"\n",
    "    text_features = []\n",
    "    processors = {}\n",
    "    \n",
    "    for col in text_columns:\n",
    "        # 训练模式\n",
    "        tfidf = TfidfVectorizer(max_features=5000)\n",
    "        svd = TruncatedSVD(n_components=n_components)\n",
    "        \n",
    "        tfidf_matrix = tfidf.fit_transform(df[col].fillna(''))\n",
    "        svd_matrix = svd.fit_transform(tfidf_matrix)\n",
    "        \n",
    "        text_features.append(svd_matrix)\n",
    "    \n",
    "    # 合并文本特征\n",
    "    text_features = np.hstack(text_features)\n",
    "    text_columns = [f'text_{i}' for i in range(text_features.shape[1])]\n",
    "    \n",
    "    return pd.DataFrame(text_features, columns=text_columns)\n",
    "\n",
    "# ================== 变量交叉验证特征生成器 ==================\n",
    "def generate_kfold_features(df, target='interaction_cnt', group_key='uid',agg_funcs=['mean', 'std', 'max']):\n",
    "    train = df[df.istest==0].copy()\n",
    "    test = df[df.istest==1].copy()\n",
    "    \n",
    "    # 生成交叉验证折号\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train['fold'] = -1\n",
    "    for fold, (_, val_idx) in enumerate(folds.split(train)):\n",
    "        train.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "    # 训练集特征生成\n",
    "    features = []\n",
    "    for func in agg_funcs:\n",
    "        feat_name = f'{group_key}_{target}_{func}'\n",
    "        train[feat_name] = 0\n",
    "        \n",
    "        # 交叉验证填充特征\n",
    "        for fold in range(5):\n",
    "            trn = train[train.fold != fold]\n",
    "            val_idx = train[train.fold == fold].index\n",
    "            \n",
    "            agg_values = trn.groupby(group_key)[target].agg(func)\n",
    "            train.loc[val_idx, feat_name] = train.loc[val_idx, group_key].map(agg_values)\n",
    "        \n",
    "        # 测试集特征\n",
    "        test_agg = train.groupby(group_key)[target].agg(func)\n",
    "        test[feat_name] = test[group_key].map(test_agg)\n",
    "        \n",
    "        features.append(feat_name)\n",
    "    \n",
    "    # 合并结果并填充缺失值\n",
    "    full_df = pd.concat([train, test], axis=0)\n",
    "    full_df[features] = full_df[features].fillna(full_df[features].mean())\n",
    "    \n",
    "    return full_df[features].reset_index(drop=True)\n",
    "\n",
    "# ================== 完整特征工程 ==================\n",
    "def build_features(df):\n",
    "    \"\"\"构建完整特征集\"\"\"\n",
    "    # 预处理\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    # 文本特征\n",
    "    text_cols = ['title', 'content', 'cover_ocr_content', 'video_content']\n",
    "    df_text = process_text_features(df, text_cols)\n",
    "    \n",
    "    # 交叉统计特征\n",
    "    df['user_site'] = df['uid'].astype(str) + '_' + df['site_id'].astype(str)\n",
    "    df['user_post'] = df['uid'].astype(str) + '_' + df['post_type'].astype(str)\n",
    "    user_features = generate_kfold_features(df, target='interaction_cnt', group_key='uid', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    user_site_features = generate_kfold_features(df, target='interaction_cnt', group_key='user_site', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    user_post_features = generate_kfold_features(df, target='interaction_cnt', group_key='user_post', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    \n",
    "    # 截至到更新日的每天平均互动量\n",
    "    df['interaction_cnt_update_delay_days'] = df['interaction_cnt'] / (df['update_delay_days'] + 1)\n",
    "    user_features2 = generate_kfold_features(df, target='interaction_cnt_update_delay_days', group_key='uid', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    user_site_features2 = generate_kfold_features(df, target='interaction_cnt_update_delay_days', group_key='user_site', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    user_post_features2 = generate_kfold_features(df, target='interaction_cnt_update_delay_days', group_key='user_post', agg_funcs=['mean', 'max', 'min', 'median'])\n",
    "    \n",
    "    # 基础特征\n",
    "    base_features = [\n",
    "        'site_id', 'gender', 'age', 'city', 'post_type', 'fans_cnt',\n",
    "        'video_cnt', 'coin_cnt', 'publish_day', 'publish_weekday', 'publish_month',\n",
    "        'update_delay_days','author_popularity','fans_video_ratio','author_power',\n",
    "        'istest','interaction_cnt'\n",
    "    ]\n",
    "    \n",
    "    # 合并所有特征\n",
    "    df_features = pd.concat([df[base_features].reset_index(drop=True),df_text,\n",
    "                             user_features,user_site_features,user_post_features,\n",
    "                             user_features2,user_site_features2,user_post_features2], axis=1)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# ================== 模型训练 ==================\n",
    "def cross_validation_train(train_features, target, test_features, cat_features):\n",
    "    \"\"\"五折交叉验证训练\"\"\"\n",
    "    import random\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random.randint(0, 10000))\n",
    "    models = []\n",
    "    oof_preds = np.zeros(len(train_features))\n",
    "    test_preds = np.zeros(len(test_features))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_features)):\n",
    "        print(f\"\\nFold {fold+1}/5\")\n",
    "        \n",
    "        X_train = train_features.iloc[train_idx]\n",
    "        y_train = target.iloc[train_idx]\n",
    "        X_val = train_features.iloc[val_idx]\n",
    "        y_val = target.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostRegressor(\n",
    "            iterations=2000,\n",
    "            learning_rate=0.1,\n",
    "            depth=7,\n",
    "            loss_function='MAE',\n",
    "            eval_metric='MAE',\n",
    "            cat_features=cat_features,\n",
    "            random_seed=random.randint(0, 10000),\n",
    "            early_stopping_rounds=200,\n",
    "            verbose=200\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            Pool(X_train, y_train, cat_features=cat_features),\n",
    "            eval_set=Pool(X_val, y_val, cat_features=cat_features)\n",
    "        )\n",
    "        \n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "        models.append(model)\n",
    "        print(f\"Fold MAE: {mean_absolute_error(y_val, oof_preds[val_idx]):.2f}\")\n",
    "        \n",
    "        test_preds += model.predict(test_features) / 5\n",
    "        \n",
    "    print(f\"\\nOOF MAE: {mean_absolute_error(target, oof_preds):.2f}\")\n",
    "    return models, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(\"智慧赢销dataset/train.txt\", sep='\\t')\n",
    "test_df = pd.read_csv(\"智慧赢销dataset/A.txt\", sep='\\t')\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# 结果文件\n",
    "result_df = test_df[['id']]\n",
    "\n",
    "# 训练集和测试集标记\n",
    "train_df['istest'] = 0\n",
    "test_df['istest'] = 1\n",
    "\n",
    "# 合并训练集和测试集\n",
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 构建特征\n",
    "df = build_features(df)\n",
    "\n",
    "# 扩展特征，根据每天平均互动量的统计结果还原互动量\n",
    "add_cols = ['uid_interaction_cnt_update_delay_days_mean','uid_interaction_cnt_update_delay_days_median',\n",
    "            'user_site_interaction_cnt_update_delay_days_mean','user_site_interaction_cnt_update_delay_days_median',\n",
    "            'user_post_interaction_cnt_update_delay_days_mean','user_post_interaction_cnt_update_delay_days_median']\n",
    "for col in add_cols:\n",
    "    df[f'restore_{col}'] = df[col] * df['update_delay_days']\n",
    "    \n",
    "cat_features = ['site_id', 'gender', 'age', 'post_type', 'city']\n",
    "\n",
    "# 缺失值填充\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].replace('', np.nan).fillna('未知')\n",
    "\n",
    "# 拆分训练集和测试集\n",
    "train_df = df[df.istest==0]\n",
    "test_df = df[df.istest==1]\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "# 入模特征\n",
    "input_cols = [f for f in train_df.columns if f not in ['istest','interaction_cnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 交叉训练建模并预测\n",
    "models, test_preds = cross_validation_train(train_df[input_cols], train_df['interaction_cnt'], test_df[input_cols], cat_features)\n",
    "\n",
    "def postprocess_predictions(preds):\n",
    "    \"\"\"确保预测结果为非负整数\"\"\"\n",
    "    preds = np.round(preds)  # 四舍五入\n",
    "    preds = np.where(preds < 0, 0, preds)  # 处理负值\n",
    "    return preds.astype(int)\n",
    "\n",
    "result_df['interaction_cnt'] = postprocess_predictions(test_preds)\n",
    "result_df['interaction_cnt'] = result_df['interaction_cnt'] / 2\n",
    "\n",
    "result_df.to_csv(\"final_results.txt\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, feature_names):\n",
    "    importance = model.get_feature_importance()\n",
    "    return pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "# 获取特征重要性\n",
    "importance_df = get_feature_importance(models[0], input_cols)\n",
    "\n",
    "# 打印表格形式的重要性\n",
    "print(\"=\"*50)\n",
    "print(\"特征重要性排序（完整列表）：\")\n",
    "print(importance_df.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
